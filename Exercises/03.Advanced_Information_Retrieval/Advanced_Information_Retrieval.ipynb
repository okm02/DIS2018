{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Advanced Information Retrieval\n",
    "\n",
    "## Question 1 - Latent Semantic Indexing\n",
    "\n",
    "\n",
    "In this exercise, we will run latent semantic indexing on a term-document matrix using python numpy library.\n",
    "\n",
    "Suppose we are given the following term-document matrix containing eleven terms and four documents $d_1$ , $d_2$ , $d_3$ and $d_4$:\n",
    "\n",
    "$\n",
    "M =\n",
    "  \\begin{bmatrix}\n",
    "    d_1 & d_2 & d_3 & d_4 \\\\ \n",
    "\t1 & 1 & 1 & 1  \\\\\n",
    "\t0 & 1 & 1 & 1 \\\\\n",
    "\t1 & 0 & 0 & 0 \\\\\n",
    "\t0 & 1 & 0 & 0 \\\\\n",
    "    1 & 0 & 0 & 0 \\\\\n",
    "    1 & 0 & 1 & 2 \\\\\n",
    "    1 & 1 & 1 & 1 \\\\\n",
    "    1 & 1 & 1 & 0 \\\\\n",
    "    1 & 0 & 0 & 0 \\\\\n",
    "    0 & 2 & 1 & 1 \\\\\n",
    "    0 & 1 & 1 & 0 \\\\\n",
    "  \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "###  Question 1.a\n",
    "\n",
    "Compute the singular value decomposition of the term-document matrix M. Print the values of the output matrices $K$, $S$ and $D^t$.\n",
    "\n",
    "\n",
    "<b>Hint:</b> Use the function numpy.linalg.svd. More details of this function can be found here at this link:\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html\n",
    "\n",
    "\n",
    "Here's sample code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Python matrix operations library\n",
    "import numpy as np\n",
    "\n",
    "#set M matrix using the given values.\n",
    "M = [[1,1,1,1], \n",
    "     [0,1,1,1],\n",
    "     [1,0,0,0],\n",
    "     [0,1,0,0],\n",
    "     [1,0,0,0],\n",
    "     [1,0,1,2],\n",
    "     [1,1,1,1],\n",
    "     [1,1,1,0],\n",
    "     [1,0,0,0],\n",
    "     [0,2,1,1],\n",
    "     [0,1,1,0]]\n",
    "\n",
    "\n",
    "M = np.array(M)\n",
    "\n",
    "# compute SVD\n",
    "K,s,Dt = np.linalg.svd(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Question 1.b\n",
    "\n",
    "Are the values of $S$ sorted? Perform latent semantic indexing by selecting the first two largest singular values of the matrix $S$.\n",
    "\n",
    "<b>Hint:</b> See the lecture slides on latent semantic indexing for more details. A sub-matrix of a numpy matrix can be computed using indexing operations (see https://docs.scipy.org/doc/numpy-1.13.0/reference/arrays.indexing.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# watch out these dimensions are nxr and rxr and rxk\n",
    "# hence watch out for d\n",
    "K_sel = K[:,0:2]\n",
    "S_sel = np.diag(s[0:2])\n",
    "Dt_sel = Dt[0:2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 1.c\n",
    "\n",
    "Given the query $q$:\n",
    "\n",
    "$\n",
    "q =\n",
    "  \\begin{bmatrix}\n",
    "\t0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 1 \\\\\n",
    "  \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "Map query $q$ into the new document space $D$. The new query is referred to as $q^*$. \n",
    "\n",
    "<b>Hint:</b> Use the formulation for mapping queries provided in the lecture slides. You can also use np.linalg.inv function for computing the inverse of a matrix.\n",
    "\n",
    "###  Question 1.d\n",
    "\n",
    "Arrange the documents based on the cosine similarity measure between $q^*$ and the new documents in the space $D$.\n",
    "\n",
    "<b>Hint:</b> Use the cosine similarity function from the previous exercise on vector space retrieval.\n",
    "\n",
    "###  Question 1.e\n",
    "\n",
    "Does the order of documents change if document $d_3$ is dropped? If yes, why? \n",
    "If no, how should $d_3$ be modified to change the document ordering?\n",
    "\n",
    "\n",
    "### Question 1.f [Optional]\n",
    "\n",
    "Run latent semantic indexing for the document collection presented in the previous exercise (presented here as well):\n",
    "\n",
    "  DocID | Document Text\n",
    "  ------|------------------\n",
    "  1     | How to Bake Breads Without Baking Recipes\n",
    "  2     | Smith Pies: Best Pies in London\n",
    "  3     | Numerical Recipes: The Art of Scientific Computing\n",
    "  4     | Breads, Pastries, Pies, and Cakes: Quantity Baking Recipes\n",
    "  5     | Pastry: A Book of Best French Pastry Recipes\n",
    "\n",
    "Now, for the query $Q=$''<i>baking</i>'', find the top ranked documents according to LSI (use three singular values). \n",
    "\n",
    "<b>Hint:</b> Use the code for computing document_vectors from the last exercise. However note that document_vectors represent document-term matrix whereas LSI uses term-document matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1c\n",
    "def create_query(q,S_sel,K_sel):\n",
    "    q = np.array(q)\n",
    "    inverse = np.linalg.inv(S_sel)\n",
    "    q_lowDim = np.dot(np.dot(q.T,K_sel),inverse)\n",
    "    return q_lowDim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1d\n",
    "def cosine_similarity(vecA,vecB):\n",
    "    prod = np.dot(vecA,vecB)\n",
    "    sizeA = np.linalg.norm(vecA,2)\n",
    "    sizeB = np.linalg.norm(vecB,2)\n",
    "    res = (prod/(sizeA * sizeB))\n",
    "    return res[0][0]\n",
    "\n",
    "\n",
    "def query_system(Dt_sel,q_lowDim):\n",
    "    D_temp = Dt_sel\n",
    "    similarities = []\n",
    "    for col in range(0,D_temp.shape[1]):\n",
    "    \n",
    "       \n",
    "        sim = cosine_similarity(q_lowDim,D_temp[:,col].reshape(-1,1))\n",
    "        similarities.append((col,sim))\n",
    "    \n",
    "    return sorted(similarities,key = lambda q : q[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, -0.012057913278690479), (3, 0.5931086268074781), (1, 0.9388827727147446), (2, 0.9524776244205609)]\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "q = [[0], \n",
    "     [0],\n",
    "     [0],\n",
    "     [0],\n",
    "     [0],\n",
    "     [1],\n",
    "     [0],\n",
    "     [0],\n",
    "     [0],\n",
    "     [1],\n",
    "     [1]]\n",
    "q_lowDim = create_query(q,S_sel,K_sel)\n",
    "print(query_system(Dt_sel,q_lowDim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.17395298953871513), (3, 0.5454101580670725), (1, 0.8644418052549182), (2, 0.9723182007460264)]\n"
     ]
    }
   ],
   "source": [
    "#1d withot doc 3\n",
    "drop_doc = np.delete(M,2,0)\n",
    "K,s,Dt = np.linalg.svd(drop_doc)\n",
    "K_sel = K[:,0:2]\n",
    "S_sel = np.diag(s[0:2])\n",
    "Dt_sel = Dt[0:2,:]\n",
    "q = [[0], \n",
    "     [0],\n",
    "     [0],\n",
    "     [0],\n",
    "     [1],\n",
    "     [0],\n",
    "     [0],\n",
    "     [0],\n",
    "     [1],\n",
    "     [1]]\n",
    "q_lowDim = create_query(q,S_sel,K_sel)\n",
    "print(query_system(Dt_sel,q_lowDim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
